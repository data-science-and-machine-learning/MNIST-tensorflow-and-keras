{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_Softmax_Classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/data-science-and-machine-learning/MNIST-tensorflow-and-keras/blob/tensorflow/Tensorflow_Softmax_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNRn7pEro8w",
        "colab_type": "text"
      },
      "source": [
        "# Softmax Classifier using TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAuadyaFro80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# credits: https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nD4hN9Gro9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p1oHQDVro9U",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "Every MNIST data point has two parts: an image of a handwritten digit and a corresponding label. We'll call the images \"x\" and the labels \"y\". Both the training set and test set contain images and their corresponding labels; for example the training images are mnist.train.images and the training labels are mnist.train.labels.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MS3H9-Kro9W",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "mnist.train.images is a tensor (an n-dimensional array) with a shape of [55000, 784]. The first dimension is an index into the list of images and the second dimension is the index for each pixel in each image. Each entry in the tensor is a pixel intensity between 0 and 1, for a particular pixel in a particular image.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v5ltd4uro9Z",
        "colab_type": "code",
        "outputId": "791b1846-c1bc-4af6-abf0-499694964f63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"number of data points : \", mnist.train.images.shape[0],\"number of pixels in each image :\",mnist.train.images.shape[1])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of data points :  55000 number of pixels in each image : 784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgaHugyNro9i",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "we're going to want our class-labels as \"one-hot vectors\". A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In this case, the t-th digit will be represented as a vector which is 1 in the t-th dimension. For example, 3 would be [0,0,0,1,0,0,0,0,0,0]. Consequently, mnist.train.labels is a [55000, 10] array of floats.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwEk7I3iro9k",
        "colab_type": "code",
        "outputId": "da985209-08fa-4349-c2fb-9bdee5bcb796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"number of data points : \", mnist.test.labels.shape[0],\" length of the one hot encoded label vector :\",mnist.test.labels.shape[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of data points :  10000  length of the one hot encoded label vector : 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iquBvcxro9s",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "If you want to assign probabilities to an object being one of several different things, softmax (Multiclass Logistic regression) is the thing to do, because softmax gives us a list of values between 0 and 1 that add up to 1. Even later on, when we train more sophisticated models, the final step will be a layer of softmax.\n",
        "\n",
        "A softmax regression has two steps: first we add up the evidence of our input being in certain classes, and then we convert that evidence into probabilities.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RiPinIxro9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5sFc2FZcro9y",
        "colab_type": "code",
        "outputId": "c59eee47-a5e8-4625-b825-81511c44e794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "# Get a list of devices like GPUs and CPUs available to TF\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 17954788452834234545\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 14299045596148172690\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 11980006402706288937\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 11326753997\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 11987763914395489484\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBpTkDAqvKmZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "311a7e08-ec33-4508-bcbf-8ed063b800cd"
      },
      "source": [
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Please install GPU version of TF\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default GPU Device: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me4O2pkUro93",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Sample Output (with a GPU) <br>\n",
        "\n",
        "[name: \"/cpu:0\" device_type: \"CPU\" memory_limit: 268435456 locality { } incarnation: 4402277519343584096,\n",
        "\n",
        "name: \"/gpu:0\" device_type: \"GPU\" memory_limit: 6772842168 locality { bus_id: 1 } incarnation: 7471795903849088328 physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0\" ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQeukILEro94",
        "colab_type": "text"
      },
      "source": [
        "### Placeholders and Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSl4cllIro95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x isn't a specific value. It's a placeholder. A placeholder can be imagained as \n",
        "# a memory unit that we use to load various mini-batches of imput data while training.\n",
        "\n",
        "\n",
        "# We want to be able to input any number of MNIST images, \n",
        "# each flattened into a 784-dimensional vector. \n",
        "\n",
        "# We represent this as a 2-D tensor of floating-point numbers, \n",
        "# with a shape [None, 784]. \n",
        "\n",
        "# (Here None means that a dimension can be of any length.)\n",
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "\n",
        "# We also need the weights and biases for our model. \n",
        "\n",
        "# We could imagine treating these like additional inputs, \n",
        "# but TensorFlow has an even better way to handle it: Variable. \n",
        "\n",
        "# A Variable is a modifiable tensor that lives in TensorFlow's graph\n",
        "# of interacting operations. \n",
        "\n",
        "# It can be used and even modified by the computation. \n",
        "# For machine learning applications, one generally has the model parameters be Variables.\n",
        "W = tf.Variable(tf.zeros([784, 10]))\n",
        "b = tf.Variable(tf.zeros([10]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6IQPfMero98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, we multiply x by W with the expression tf.matmul(x, W). \n",
        "# This is flipped from when we multiplied them in our equation, \n",
        "# where we had Wx , as a small trick to deal with x being a 2D tensor \n",
        "# with multiple inputs. \n",
        "\n",
        "# We then add b, and finally apply tf.nn.softmax.\n",
        "y = tf.nn.softmax(tf.matmul(x, W) + b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kabqZYcaro9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_ is true label of the images, and similar to x\n",
        "y_ = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "\n",
        "# Defining the loss function: multi class log-loss/cross-entropy\n",
        "# First, tf.log computes the logarithm of each element of y. \n",
        "\n",
        "# Next, we multiply each element of y_ with the corresponding element \n",
        "# of tf.log(y). \n",
        "\n",
        "# Then tf.reduce_sum adds the elements in the second dimension of y, \n",
        "# due to the reduction_indices=[1] parameter. \n",
        "\n",
        "#Tutorial for tf.reduce_sum: https://www.dotnetperls.com/reduce-sum-tensorflow\n",
        "\n",
        "# Reduction is an operation that removes one or more dimensions from a tensor by performing \n",
        "# certain operations across those dimensions.\n",
        "\n",
        "# Finally, tf.reduce_mean computes the mean over all the examples in the batch.\n",
        "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vREdzNYPro-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In this case, we ask TensorFlow to minimize cross_entropy \n",
        "# using the gradient descent algorithm with a learning rate of 0.05.\n",
        "\n",
        "# https://www.tensorflow.org/versions/r1.2/api_guides/python/train#Optimizers\n",
        "\n",
        "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)\n",
        "\n",
        "# What TensorFlow actually does here, behind the scenes,\n",
        "# is to add new operations to your computation-graph which implement backpropagation and gradient descent.\n",
        "# Then it gives you back a single operation which, when run, does a step of gradient descent training, \n",
        "# slightly tweaking your variables to reduce the loss."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DmJqAN3ro-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can now launch the model in an InteractiveSession\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "# We first have to create an operation to initialize the \n",
        "# variables we created:\n",
        "tf.global_variables_initializer().run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9dHQaw-ro-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Each step of the loop, we get a \"mini-batch\" of one hundred random data \n",
        "# points from our training set. \n",
        "\n",
        "# We run train_step feeding in the batches data to replace \n",
        "# the placeholders\n",
        "for _ in range(1000):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
        "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
        "\n",
        "# Using small batches of random data is called stochastic training -- in this case, stochastic gradient descent. \n",
        "# Ideally, we'd like to use all our data for every step of training because that would give us a better sense of\n",
        "# what we should be doing, but that's expensive. So, instead, we use a different subset every time. \n",
        "# Doing this is cheap and has much of the same benefit."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02cd-K4uro-Q",
        "colab_type": "code",
        "outputId": "3261b2a6-277d-40df-a83f-cd31a32b6c1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://stackoverflow.com/a/41863099\n",
        "# tf.argmax(input, axis=None, name=None, dimension=None)\n",
        "# Returns the index with the largest value across axis of a tensor.\n",
        "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ian22lpAro-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\n",
        "# https://stackoverflow.com/a/14434334\n",
        "def plt_dynamic(x, y, y_1, ax, colors=['b']):\n",
        "    ax.plot(x, y, 'b', label=\"Train Loss\")\n",
        "    ax.plot(x, y_1, 'r', label=\"Test Loss\")\n",
        "    if len(x)==1:\n",
        "        plt.legend()\n",
        "    fig.canvas.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "6ECWKXHiro-b",
        "colab_type": "code",
        "outputId": "ec290f90-4488-42ec-a7bd-6f54a1fe1f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "# summarizing everything in single cell\n",
        "%matplotlib inline\n",
        "training_epochs = 15\n",
        "batch_size = 1000\n",
        "display_step = 1\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y, labels = y_))\n",
        "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)\n",
        "\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.set_xlabel('epoch') ; ax.set_ylabel('Soft Max Cross Entropy loss')\n",
        "xs, ytrs, ytes = [], [], []\n",
        "for epoch in range(training_epochs):\n",
        "        train_avg_cost = 0.\n",
        "        test_avg_cost = 0.\n",
        "        total_batch = int(mnist.train.num_examples/batch_size)\n",
        "        # Loop over all batches\n",
        "        for i in range(total_batch):\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "            _, c = sess.run([train_step, cross_entropy], feed_dict={x: batch_xs, y_: batch_ys})\n",
        "            train_avg_cost += c / total_batch\n",
        "            c = sess.run(cross_entropy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
        "            test_avg_cost += c / total_batch\n",
        "\n",
        "        xs.append(epoch)\n",
        "        ytrs.append(train_avg_cost)\n",
        "        ytes.append(test_avg_cost)\n",
        "        plt_dynamic(xs, ytrs, ytes, ax)\n",
        "        \n",
        "\n",
        "plt_dynamic(xs, ytrs, ytes, ax)\n",
        "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y_: mnist.test.labels}))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeZPhPXCvSxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}